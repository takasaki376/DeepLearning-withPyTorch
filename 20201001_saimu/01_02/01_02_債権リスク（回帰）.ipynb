{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 訓練データと検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "# データを扱う\n",
    "import pandas as pd\n",
    "# グラフ描画\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# 特徴量選択\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# 多項式・交互作用特徴量\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math\n",
    "# 評価関数（f1_score）\n",
    "from sklearn.metrics import f1_score \n",
    "# 混同行列\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 自動微分の関数 \n",
    "from torch.autograd import Variable\n",
    "# ニューラルネットワークの関数\n",
    "import torch.nn as nn\n",
    "# 活性化関数\n",
    "import torch.nn.functional as F\n",
    "# 最適化のアルゴリズムの関数\n",
    "import torch.optim as optim\n",
    "#ユーティリティのデータから\n",
    "from torch.utils.data import DataLoader ,TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # CSVファイル読み込み（訓練データ）\n",
    "        df = pd.read_csv('train.csv')\n",
    "        \n",
    "        # 不正データの補正 (レコード削除のパターンもあるため、ファイル読み込み直後に処理する)\n",
    "        df = self.correction(df)\n",
    "        \n",
    "        # 説明変数と目的変数に分割する\n",
    "        df_x = df.drop(['loan_status'], axis=1)\n",
    "        self.df_y = df.loc[:,['loan_status']]\n",
    "        self.targetConv()\n",
    "        \n",
    "        # 説明変数の量的データ、質的データ分割\n",
    "        self.x_cate , self.x_cont, self.x_id = self.DataChange(df_x.copy())\n",
    "        self.x_desc = self.x_cont.describe()\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate.copy()\n",
    "        self.x_cont_conv = self.x_cont.copy()\n",
    "        \n",
    "        # データの加工（標準化や対数化など）\n",
    "        #self.std_scale = 0\n",
    "        #self.max_scale = 0\n",
    "        #self.dobule_scale = 0\n",
    "        #self.polynomialFlg = 0\n",
    "        #self.binSplitFlg = 0\n",
    "        self.logFlg = 0\n",
    "        self.DataConv()\n",
    "        \n",
    "        #self.NpToPy()\n",
    "        #self.num = len(self.X_train)\n",
    "        self.num = len(self.x_cont)\n",
    "        self.coti_size = self.x_cont.shape[1]\n",
    "        \n",
    "    def correction(self, df):\n",
    "        \n",
    "        print('null check')\n",
    "        print(df.isnull().sum())\n",
    "        print('-------------------------')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def viewDescribe(self):\n",
    "        self.x_cont.describe()\n",
    "        self.x_cate.describe(include='O')\n",
    "    \n",
    "    def dropCol(self):\n",
    "        \n",
    "        #self.x_cate_conv = self.x_cate_conv.drop(columns=['employment_length'], axis=1)\n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=['employment_length','application_type'], axis=1)\n",
    "        # application_type  は使ってみる\n",
    "        \n",
    "        #self.x_cont_conv = self.x_cont_conv.drop(columns=['loan_amnt'], axis=1)\n",
    "        self.x_cont_conv = self.x_cont_conv.drop(columns=['loan_amnt','credit_score'], axis=1)\n",
    "        # credit_score  は使ってみる（差があるかは要確認）\n",
    "        \n",
    "    def DataChange(self, df_x):\n",
    "        categ_cols = ['term' ,'grade' ,'employment_length', 'purpose' ,'application_type']\n",
    "        contin_cols = ['loan_amnt', 'interest_rate', 'credit_score']\n",
    "        index_cols = ['id']\n",
    "\n",
    "        ####################################\n",
    "        ##  データ分割\n",
    "        ##  説明変数と目的変数に分ける。\n",
    "        ##  説明変数はカテゴリデータと連続データに分ける。\n",
    "        ####################################\n",
    "        x_cate = df_x[categ_cols].copy()\n",
    "        x_cont = df_x[contin_cols].copy()\n",
    "        x_id = df_x[index_cols].copy()\n",
    "        x_id = x_id.astype('int64')\n",
    "        \n",
    "        return x_cate , x_cont  ,x_id\n",
    "    \n",
    "    def targetConv(self):\n",
    "        self.df_y = self.df_y.replace('FullyPaid', '0').replace('ChargedOff', '1')\n",
    "        self.df_y.astype('float32')\n",
    "        \n",
    "    def NpToPy(self):\n",
    "        \n",
    "        #tmp = self.x_cont[['displacement_log', 'horsepower_log', 'weight_log', 'acceleration_log']]\n",
    "        #tmp = self.x_cont[['horsepower_log', 'weight_log', 'acceleration_log']]\n",
    "        \n",
    "        x_temp = pd.concat([self.x_cate_conv , self.x_cont_conv] , axis=1)\n",
    "        self.train_x_col_name = x_temp.columns.values\n",
    "        #x_temp = self.x_cont.copy()\n",
    "        x_temp = np.array(x_temp)\n",
    "        y_temp = np.array(self.df_y, dtype=np.float64)\n",
    "        self.train_y_col_name = self.df_y.columns.values\n",
    "        \n",
    "        # 訓練データと検証データに分割\n",
    "        x_train,x_test,y_train,y_test=train_test_split(x_temp, y_temp, test_size=0.2, random_state=3) \n",
    "        \n",
    "        # \n",
    "        self.X_train = x_train\n",
    "        self.Y_train = y_train\n",
    "        self.X_test = x_test\n",
    "        self.Y_test = y_test\n",
    "        \n",
    "        #self.downSampling()\n",
    "        \n",
    "        self.coti_size = self.x_cont.shape[1]\n",
    "        self.in_size  = self.X_train.shape[1]\n",
    "        self.out_size = self.Y_train.shape[1]  \n",
    "\n",
    "    def downSampling(self):\n",
    "        \n",
    "        x = pd.DataFrame(self.X_train ,columns=self.train_x_col_name)\n",
    "        y = pd.DataFrame(self.Y_train ,columns=self.train_y_col_name)\n",
    "        \n",
    "        train = pd.concat([x, y] ,axis=1)\n",
    "\n",
    "        # 完済のデータと貸し倒れのデータを別々の変数に代入\n",
    "        fp = train.loc[train['loan_status'] == 0, :]\n",
    "        co = train[train['loan_status'] == 1]\n",
    "        \n",
    "        print('fp_cnt=', len(fp))\n",
    "        print('co_cnt=', len(co))\n",
    "        # 貸し倒れのデータ数と同じ数だけ完済のデータをランダムに取り出し\n",
    "        fp = fp.sample(n=co.shape[0], random_state=0)\n",
    "        print('fp_cnt=', len(fp))\n",
    "        \n",
    "        # 完済のデータと貸し倒れのデータを縦結合\n",
    "        train = pd.concat([fp, co] ,axis=0)\n",
    "\n",
    "        # 説明変数と目的変数をそれぞれ別の変数に代入\n",
    "        self.X_train_sample = train.drop(columns=['loan_status'] ,axis=1)\n",
    "        self.Y_train_sample = train['loan_status']\n",
    "\n",
    "    \n",
    "    def termConv(self):\n",
    "        \n",
    "        col = 'term'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='3 years']\n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        # ALL ゼロが5 yearsなので処理しない\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='5 years']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "    \n",
    "    def gradeConv(self):\n",
    "        \n",
    "        col = 'grade'\n",
    "        \n",
    "        self.x_cate_conv[col + '_01'] = 0\n",
    "        self.x_cate_conv[col + '_02'] = 0\n",
    "        self.x_cate_conv[col + '_03'] = 0\n",
    "        self.x_cate_conv[col + '_04'] = 0\n",
    "        self.x_cate_conv[col + '_05'] = 0\n",
    "        \n",
    "        #self.x_cate_conv[col + '_06'] = 0\n",
    "        #self.x_cate_conv[col + '_07'] = 0\n",
    "        #self.x_cate_conv[col + '_08'] = 0\n",
    "        #self.x_cate_conv[col + '_09'] = 0\n",
    "        #self.x_cate_conv[col + '_10'] = 0\n",
    "        \n",
    "        #self.x_cate_conv[col + '_11'] = 0\n",
    "        #self.x_cate_conv[col + '_12'] = 0\n",
    "        #self.x_cate_conv[col + '_13'] = 0\n",
    "        #self.x_cate_conv[col + '_14'] = 0\n",
    "        #self.x_cate_conv[col + '_15'] = 0\n",
    "        \n",
    "        #self.x_cate_conv[col + '_16'] = 0\n",
    "        #self.x_cate_conv[col + '_17'] = 0\n",
    "        #self.x_cate_conv[col + '_18'] = 0\n",
    "        #self.x_cate_conv[col + '_19'] = 0\n",
    "        #self.x_cate_conv[col + '_20'] = 0        \n",
    "\n",
    "        #self.x_cate_conv[col + '_21'] = 0\n",
    "        #self.x_cate_conv[col + '_22'] = 0\n",
    "        #self.x_cate_conv[col + '_23'] = 0\n",
    "        #self.x_cate_conv[col + '_24'] = 0\n",
    "        #self.x_cate_conv[col + '_25'] = 0\n",
    "        \n",
    "        #self.x_cate_conv[col + '_26'] = 0\n",
    "        #self.x_cate_conv[col + '_27'] = 0\n",
    "        #self.x_cate_conv[col + '_28'] = 0\n",
    "        #self.x_cate_conv[col + '_29'] = 0\n",
    "            \n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='A1']\n",
    "        self.x_cate_conv.loc[row_index, col + '_01'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='A2']\n",
    "        self.x_cate_conv.loc[row_index, col + '_01'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='A3']\n",
    "        self.x_cate_conv.loc[row_index, col + '_01'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='A4']\n",
    "        self.x_cate_conv.loc[row_index, col + '_01'] = 1        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='A5']\n",
    "        self.x_cate_conv.loc[row_index, col + '_01'] = 1     \n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='B1']\n",
    "        self.x_cate_conv.loc[row_index, col + '_02'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='B2']\n",
    "        self.x_cate_conv.loc[row_index, col + '_02'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='B3']\n",
    "        self.x_cate_conv.loc[row_index, col + '_02'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='B4']\n",
    "        self.x_cate_conv.loc[row_index, col + '_02'] = 1        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='B5']\n",
    "        self.x_cate_conv.loc[row_index, col + '_02'] = 1  \n",
    " \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='C1']\n",
    "        self.x_cate_conv.loc[row_index, col + '_03'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='C2']\n",
    "        self.x_cate_conv.loc[row_index, col + '_03'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='C3']\n",
    "        self.x_cate_conv.loc[row_index, col + '_03'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='C4']\n",
    "        self.x_cate_conv.loc[row_index, col + '_03'] = 1        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='C5']\n",
    "        self.x_cate_conv.loc[row_index, col + '_03'] = 1     \n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='D1']\n",
    "        self.x_cate_conv.loc[row_index, col + '_04'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='D2']\n",
    "        self.x_cate_conv.loc[row_index, col + '_04'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='D3']\n",
    "        self.x_cate_conv.loc[row_index, col + '_04'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='D4']\n",
    "        self.x_cate_conv.loc[row_index, col + '_04'] = 1        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='D5']\n",
    "        self.x_cate_conv.loc[row_index, col + '_04'] = 1  \n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='E1']\n",
    "        self.x_cate_conv.loc[row_index, col + '_05'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='E2']\n",
    "        self.x_cate_conv.loc[row_index, col + '_05'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='E3']\n",
    "        self.x_cate_conv.loc[row_index, col + '_05'] = 1\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='E4']\n",
    "        self.x_cate_conv.loc[row_index, col + '_05'] = 1        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='E5']\n",
    "        self.x_cate_conv.loc[row_index, col + '_05'] = 1     \n",
    " \n",
    "        # ALL ゼロがF5なので処理しない\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='F1']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='F2']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='F3']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='F4']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='F5']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "        \n",
    "        \n",
    "    def purposeConv(self):\n",
    "        \n",
    "        col = 'purpose'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "        self.x_cate_conv[col + '_2'] = 0\n",
    "        self.x_cate_conv[col + '_3'] = 0\n",
    "        self.x_cate_conv[col + '_4'] = 0\n",
    "        self.x_cate_conv[col + '_5'] = 0\n",
    "        self.x_cate_conv[col + '_6'] = 0 \n",
    "        self.x_cate_conv[col + '_7'] = 0\n",
    "        self.x_cate_conv[col + '_8'] = 0\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='car']\n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='credit_card']\n",
    "        self.x_cate_conv.loc[row_index, col + '_2'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='debt_consolidation']\n",
    "        self.x_cate_conv.loc[row_index, col + '_3'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='home_improvement']\n",
    "        self.x_cate_conv.loc[row_index, col + '_4'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='house']\n",
    "        self.x_cate_conv.loc[row_index, col + '_5'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='major_purchase']\n",
    "        self.x_cate_conv.loc[row_index, col + '_6'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='medical']\n",
    "        self.x_cate_conv.loc[row_index, col + '_7'] = 1\n",
    "        \n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='small_business']\n",
    "        self.x_cate_conv.loc[row_index, col + '_8'] = 1\n",
    "        \n",
    "        # ALL ゼロがotherなので処理しない\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='other']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "        \n",
    "    def appConv(self):\n",
    "        \n",
    "        col = 'application_type'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='Individual']\n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        # ALL ゼロがJoint Appなので処理しない\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='Joint App']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    " \n",
    "    def binSplit(self):\n",
    "        contin_cols = self.x_cont_conv.columns.values\n",
    "\n",
    "        for col in contin_cols:\n",
    "            split_min = 0\n",
    "            split_min2 = self.x_desc.loc['min',col]\n",
    "            split1 = self.x_desc.loc['25%',col]\n",
    "            split2 = self.x_desc.loc['50%',col]\n",
    "            split3 = self.x_desc.loc['75%',col]\n",
    "            std_m = self.x_desc.loc['std',col]/3\n",
    "            std_p = self.x_desc.loc['std',col]*3\n",
    "            split_max=  self.x_desc.loc['max',col]\n",
    "            split_max2=  self.x_desc.loc['max',col]*10\n",
    "            bins = [split_min,  split_min2, split1,  split2,  split3, std_m,  std_p,  split_max, split_max2]\n",
    "            bins = np.sort(bins)\n",
    "            self.x_cont_conv[col] = pd.cut(self.x_cont_conv[col], bins=bins, labels=False)\n",
    "    \n",
    "    def binSplit2(self):\n",
    "        contin_cols = self.x_cont_conv.columns.values\n",
    "\n",
    "        for col in contin_cols:\n",
    "            \n",
    "            bins = 30\n",
    "            self.x_cont_conv[col] = pd.cut(self.x_cont_conv[col], bins=bins ,labels=False)\n",
    "            \n",
    "    def DataConv(self):\n",
    "\n",
    "        self.termConv()\n",
    "        self.gradeConv()\n",
    "        self.purposeConv()\n",
    "        #self.appConv()\n",
    "        #self.binSplit2()\n",
    "        self.dropCol()        \n",
    "        self.NpToPy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null check\n",
      "id                   0\n",
      "loan_amnt            0\n",
      "term                 0\n",
      "interest_rate        0\n",
      "grade                0\n",
      "employment_length    0\n",
      "purpose              0\n",
      "credit_score         0\n",
      "application_type     0\n",
      "loan_status          0\n",
      "dtype: int64\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_1</th>\n",
       "      <th>grade_01</th>\n",
       "      <th>grade_02</th>\n",
       "      <th>grade_03</th>\n",
       "      <th>grade_04</th>\n",
       "      <th>grade_05</th>\n",
       "      <th>purpose_1</th>\n",
       "      <th>purpose_2</th>\n",
       "      <th>purpose_3</th>\n",
       "      <th>purpose_4</th>\n",
       "      <th>purpose_5</th>\n",
       "      <th>purpose_6</th>\n",
       "      <th>purpose_7</th>\n",
       "      <th>purpose_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242146</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242147</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242148</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242149</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242150 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_1  grade_01  grade_02  grade_03  grade_04  grade_05  purpose_1  \\\n",
       "0            1         1         0         0         0         0          0   \n",
       "1            0         0         1         0         0         0          0   \n",
       "2            1         0         0         1         0         0          0   \n",
       "3            1         0         0         1         0         0          0   \n",
       "4            0         0         0         0         0         1          0   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "242145       1         0         1         0         0         0          0   \n",
       "242146       1         0         1         0         0         0          0   \n",
       "242147       1         1         0         0         0         0          0   \n",
       "242148       1         0         0         1         0         0          0   \n",
       "242149       1         0         0         0         1         0          0   \n",
       "\n",
       "        purpose_2  purpose_3  purpose_4  purpose_5  purpose_6  purpose_7  \\\n",
       "0               0          1          0          0          0          0   \n",
       "1               1          0          0          0          0          0   \n",
       "2               0          1          0          0          0          0   \n",
       "3               1          0          0          0          0          0   \n",
       "4               0          1          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "242145          0          1          0          0          0          0   \n",
       "242146          0          1          0          0          0          0   \n",
       "242147          0          0          0          0          0          0   \n",
       "242148          0          1          0          0          0          0   \n",
       "242149          0          1          0          0          0          0   \n",
       "\n",
       "        purpose_8  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "242145          0  \n",
       "242146          0  \n",
       "242147          0  \n",
       "242148          0  \n",
       "242149          0  \n",
       "\n",
       "[242150 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x_cate_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>credit_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>242150.000000</td>\n",
       "      <td>242150.000000</td>\n",
       "      <td>242150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1520.389009</td>\n",
       "      <td>13.801496</td>\n",
       "      <td>683.575024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>830.250197</td>\n",
       "      <td>4.588924</td>\n",
       "      <td>29.554795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>323.797279</td>\n",
       "      <td>5.704849</td>\n",
       "      <td>655.424269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>761.954545</td>\n",
       "      <td>10.876086</td>\n",
       "      <td>659.531106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1212.680586</td>\n",
       "      <td>13.543833</td>\n",
       "      <td>678.672563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2152.213330</td>\n",
       "      <td>17.172395</td>\n",
       "      <td>698.591960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3851.867974</td>\n",
       "      <td>27.980604</td>\n",
       "      <td>808.551641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           loan_amnt  interest_rate   credit_score\n",
       "count  242150.000000  242150.000000  242150.000000\n",
       "mean     1520.389009      13.801496     683.575024\n",
       "std       830.250197       4.588924      29.554795\n",
       "min       323.797279       5.704849     655.424269\n",
       "25%       761.954545      10.876086     659.531106\n",
       "50%      1212.680586      13.543833     678.672563\n",
       "75%      2152.213330      17.172395     698.591960\n",
       "max      3851.867974      27.980604     808.551641"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, x_desc):\n",
    "        \n",
    "        # CSVファイル読み込み（訓練データ）\n",
    "        df = pd.read_csv('test.csv' )\n",
    "        self.df_data = df.copy()\n",
    "        # 不正データの補正 (レコード削除のパターンもあるため、ファイル読み込み直後に処理する)\n",
    "        df = self.correction(df)\n",
    "        \n",
    "        # 目的変数の格納\n",
    "        self.x_cate , self.x_cont, self.x_id = self.DataChange(df.copy())\n",
    "        self.x_desc = x_desc\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate.copy()\n",
    "        self.x_cont_conv = self.x_cont.copy()\n",
    "        \n",
    "        # データの加工（標準化や対数化など）\n",
    "        #self.std_scale = 0\n",
    "        #self.max_scale = 0\n",
    "        #self.dobule_scale = 0\n",
    "        #self.polynomialFlg = 0\n",
    "        #self.binSplitFlg = 0\n",
    "        self.logFlg  = 0\n",
    "        self.DataConv()\n",
    "        \n",
    "        #self.NpToPy()\n",
    "        #self.num = len(self.x_cate)\n",
    "        self.num = len(self.x_cont)\n",
    "        self.coti_size = self.x_cont.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_test[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "    \n",
    "    def NpToPy(self):\n",
    "        \n",
    "        x_temp = pd.concat([self.x_cate_conv , self.x_cont_conv] , axis=1)\n",
    "        \n",
    "        #x_temp = self.x_cont.copy()\n",
    "        x_temp = np.array(x_temp)\n",
    "        \n",
    "        # numpy の値を torch の値に変換する\n",
    "        self.X_vat = x_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null check\n",
      "id                   0\n",
      "loan_amnt            0\n",
      "term                 0\n",
      "interest_rate        0\n",
      "grade                0\n",
      "employment_length    0\n",
      "purpose              0\n",
      "credit_score         0\n",
      "application_type     0\n",
      "dtype: int64\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(train_dataset.x_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26895</th>\n",
       "      <td>269045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26896</th>\n",
       "      <td>269046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26897</th>\n",
       "      <td>269047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26898</th>\n",
       "      <td>269048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26899</th>\n",
       "      <td>269049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26900 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id\n",
       "0      242150\n",
       "1      242151\n",
       "2      242152\n",
       "3      242153\n",
       "4      242154\n",
       "...       ...\n",
       "26895  269045\n",
       "26896  269046\n",
       "26897  269047\n",
       "26898  269048\n",
       "26899  269049\n",
       "\n",
       "[26900 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.x_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'TrainDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-78d6288df97e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# shuffle    : データをランダムに並び替える場合はTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#train_loader = DataLoader(train ,batch_size=30, shuffle=True, num_workers=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# map-style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[0;32m     90\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m     94\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# dataset size might change at runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'TrainDataset' has no len()"
     ]
    }
   ],
   "source": [
    "batchsize=500\n",
    "\n",
    "# batch_size ：学習する時にまとめるデータ数\n",
    "# shuffle    : データをランダムに並び替える場合はTrue\n",
    "#train_loader = DataLoader(train ,batch_size=30, shuffle=True, num_workers=2)\n",
    "train_loader = DataLoader(dataset=train_dataset ,batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.1408038601714491\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(train_dataset.X_train)\n",
    "#y_pred_train = model.predict_proba(train_dataset.X_train)\n",
    "print(y_pred_train)\n",
    "score_train = f1_score(train_dataset.Y_train, y_pred_train)\n",
    "\n",
    "# f1_scoreの表示\n",
    "print(score_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1408038601714491\n"
     ]
    }
   ],
   "source": [
    "# f1_scoreの表示\n",
    "print(score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[157501,   2308],\n",
       "       [ 31168,   2743]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混同行列\n",
    "confusion_matrix(train_dataset.Y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.90    159809\n",
      "         1.0       0.58      0.09      0.15     33911\n",
      "\n",
      "    accuracy                           0.83    193720\n",
      "   macro avg       0.71      0.54      0.53    193720\n",
      "weighted avg       0.79      0.83      0.77    193720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.99      0.90    159809\n",
      "         1.0       0.54      0.08      0.14     33911\n",
      "\n",
      "    accuracy                           0.83    193720\n",
      "   macro avg       0.69      0.53      0.52    193720\n",
      "weighted avg       0.78      0.83      0.77    193720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14168142514845297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_test = model.predict(train_dataset.X_test)\n",
    "score_test = f1_score(train_dataset.Y_test, y_pred_test)\n",
    "\n",
    "# f1_scoreの表示\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39527,   458],\n",
       "       [ 7703,   742]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混同行列\n",
    "confusion_matrix(train_dataset.Y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39511,   474],\n",
       "       [ 7765,   680]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混同行列\n",
    "confusion_matrix(train_dataset.Y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91     39985\n",
      "         1.0       0.62      0.09      0.15      8445\n",
      "\n",
      "    accuracy                           0.83     48430\n",
      "   macro avg       0.73      0.54      0.53     48430\n",
      "weighted avg       0.80      0.83      0.78     48430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.99      0.91     39985\n",
      "         1.0       0.59      0.08      0.14      8445\n",
      "\n",
      "    accuracy                           0.83     48430\n",
      "   macro avg       0.71      0.53      0.52     48430\n",
      "weighted avg       0.79      0.83      0.77     48430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 閾値変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takasaki\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\Users\\takasaki\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(train_dataset.X_train, train_dataset.Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測する "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1\n",
      "0       0.836731  0.163269\n",
      "1       0.823940  0.176060\n",
      "2       0.905606  0.094394\n",
      "3       0.875551  0.124449\n",
      "4       0.869322  0.130678\n",
      "...          ...       ...\n",
      "193715  0.869121  0.130879\n",
      "193716  0.810747  0.189253\n",
      "193717  0.882240  0.117760\n",
      "193718  0.809308  0.190692\n",
      "193719  0.771722  0.228278\n",
      "\n",
      "[193720 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict_proba(train_dataset.X_train)\n",
    "\n",
    "df_pred_train = pd.DataFrame(y_pred_train)\n",
    "print(df_pred_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2385365529171763\n"
     ]
    }
   ],
   "source": [
    "# 予測結果から閾値の算出\n",
    "chargedoff_val = train_dataset.Y_train.sum()\n",
    "chargedoff_val = int(chargedoff_val)\n",
    "proba_desc = df_pred_train[1].sort_values(ascending = False)\n",
    "threshold = proba_desc.iat[chargedoff_val]\n",
    "print(threshold)\n",
    "\n",
    "\n",
    "def classification(x):\n",
    "    #print(len(x))\n",
    "    \n",
    "    if len(x) == 1:\n",
    "        if x >= threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        tmp = np.zeros(len(x) ,dtype=np.int32)\n",
    "        for i in range(len(x)):\n",
    "            if x[i] >= threshold:\n",
    "                tmp[i] = 1\n",
    "            \n",
    "        return tmp\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3493210267903219\n"
     ]
    }
   ],
   "source": [
    "pred_tmp = classification(np.array(df_pred_train[1]))\n",
    "score_train = f1_score(train_dataset.Y_train, pred_tmp)\n",
    "# f1_scoreの表示\n",
    "print(score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137743,  22066],\n",
       "       [ 22065,  11846]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混同行列\n",
    "confusion_matrix(train_dataset.Y_train, pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86    159809\n",
      "         1.0       0.35      0.35      0.35     33911\n",
      "\n",
      "    accuracy                           0.77    193720\n",
      "   macro avg       0.61      0.61      0.61    193720\n",
      "weighted avg       0.77      0.77      0.77    193720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_train, pred_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1\n",
      "0      0.529708  0.470292\n",
      "1      0.796891  0.203109\n",
      "2      0.900092  0.099908\n",
      "3      0.957621  0.042379\n",
      "4      0.887447  0.112553\n",
      "...         ...       ...\n",
      "48425  0.821583  0.178417\n",
      "48426  0.741114  0.258886\n",
      "48427  0.914780  0.085220\n",
      "48428  0.906106  0.093894\n",
      "48429  0.819576  0.180424\n",
      "\n",
      "[48430 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict_proba(train_dataset.X_test)\n",
    "\n",
    "df_pred_test = pd.DataFrame(y_pred_test)\n",
    "print(df_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3517876360157838\n"
     ]
    }
   ],
   "source": [
    "pred_tmp = classification(np.array(df_pred_test[1]))\n",
    "score_train = f1_score(train_dataset.Y_test,pred_tmp )\n",
    "# f1_scoreの表示\n",
    "print(score_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34646,  5339],\n",
       "       [ 5503,  2942]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混同行列\n",
    "confusion_matrix(train_dataset.Y_test, pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.87      0.86     39985\n",
      "         1.0       0.36      0.35      0.35      8445\n",
      "\n",
      "    accuracy                           0.78     48430\n",
      "   macro avg       0.61      0.61      0.61     48430\n",
      "weighted avg       0.77      0.78      0.78     48430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_dataset.Y_test, pred_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1\n",
      "0      0.866944  0.133056\n",
      "1      0.775533  0.224467\n",
      "2      0.961154  0.038846\n",
      "3      0.961969  0.038031\n",
      "4      0.868598  0.131402\n",
      "...         ...       ...\n",
      "26895  0.854104  0.145896\n",
      "26896  0.967200  0.032800\n",
      "26897  0.897568  0.102432\n",
      "26898  0.882416  0.117584\n",
      "26899  0.955727  0.044273\n",
      "\n",
      "[26900 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred_vat = model.predict_proba(test_dataset.X_vat)\n",
    "\n",
    "df_pred_vat = pd.DataFrame(y_pred_vat)\n",
    "print(df_pred_vat)\n",
    "pred_tmp = classification(np.array(df_pred_vat[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>242152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>242153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26895</th>\n",
       "      <td>269045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26896</th>\n",
       "      <td>269046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26897</th>\n",
       "      <td>269047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26898</th>\n",
       "      <td>269048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26899</th>\n",
       "      <td>269049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  val\n",
       "0      242150    0\n",
       "1      242151    0\n",
       "2      242152    0\n",
       "3      242153    0\n",
       "4      242154    0\n",
       "...       ...  ...\n",
       "26895  269045    0\n",
       "26896  269046    0\n",
       "26897  269047    0\n",
       "26898  269048    0\n",
       "26899  269049    0\n",
       "\n",
       "[26900 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame(pred_tmp, columns=['val'])\n",
    "df_out = pd.concat([test_dataset.x_id['id'] ,df_out['val']] , axis=1)\n",
    "df_out.to_csv('./submit.csv', encoding='utf_8_sig' , header=False ,index=False)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
