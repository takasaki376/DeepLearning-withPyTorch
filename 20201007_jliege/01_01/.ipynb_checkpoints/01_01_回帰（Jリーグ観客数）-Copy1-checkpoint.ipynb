{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 訓練データと検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "# データを扱う\n",
    "import pandas as pd\n",
    "# グラフ描画\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重回帰\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "# 評価関数\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset():\n",
    "    def __init__(self):        \n",
    "        \n",
    "        # 学習データ\n",
    "        data = pd.read_csv('train.csv')\n",
    "        data_add = pd.read_csv('train_add.csv')\n",
    "        data_new = pd.concat([data, data_add])\n",
    "        \n",
    "        # スタジアム\n",
    "        self.stadium = pd.read_csv('stadium.csv')\n",
    "        data_all = pd.merge(data_new, self.stadium, left_on='stadium', right_on='name', how='left') \n",
    "        \n",
    "        # data_allのnameカラムを削除して、data_allに代入してください。\n",
    "        data_all = data_all.drop(columns=['name'])\n",
    "        \n",
    "        # 不正データの補正 (レコード削除のパターンもあるため、ファイル読み込み直後に処理する)\n",
    "        self.df = self.correction(data_all.copy())\n",
    "        \n",
    "        # 目的変数の外れ値は、評価データに存在しないため、init内で処理する\n",
    "        self.df = self.df[self.df['y'] > 0]\n",
    "        self.df['y_capa'] = self.df['y'] / self.df['capa']\n",
    "        \n",
    "        # 説明変数と目的変数に分割する\n",
    "        df_x = self.df.drop(['y', 'y_capa'], axis=1)\n",
    "        self.df_y = self.df.loc[:,['y']]\n",
    "        self.df_y_capa = self.df.loc[:,['y_capa']]\n",
    "        \n",
    "        \n",
    "        # 説明変数の量的データ、質的データ分割\n",
    "        self.x_cate , self.x_cont, self.x_id = self.DataChange(df_x.copy())\n",
    "        self.x_desc = self.x_cont.describe()\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate.copy()\n",
    "        self.x_cont_conv = self.x_cont.copy()\n",
    "        \n",
    "        self.DataConv()\n",
    "        \n",
    "        print(self.x_cate_conv.info())\n",
    "        print(self.x_cont_conv.info())\n",
    "        \n",
    "    def correction(self, df):\n",
    "\n",
    "        df['month'] = df['gameday'].apply(self.get_month)\n",
    "        df['week'] = df['gameday'].apply(self.get_week)\n",
    "        df['match_num'] = df['match'].apply(self.get_match)\n",
    "        df['hour'] = df['time'].apply(self.get_hour)\n",
    "        df['tv_num'] = df['tv'].apply(self.get_num)\n",
    "        df = df.replace('ザスパ草津','ザスパクサツ群馬')\n",
    "        df = df.replace('岐阜メモリアルセンター長良川球技メドウ','岐阜メモリアルセンター長良川競技場')\n",
    "        \n",
    "        #print('null check')\n",
    "        #print(df.isnull().sum())\n",
    "        #print('-------------------------')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def DataChange(self, df_x):\n",
    "        categ_cols = ['stage' ,'month', 'gameday', 'tv', 'week']\n",
    "        contin_cols = ['year', 'match_num' ,'tv_num']\n",
    "        index_cols = ['id', 'capa']\n",
    "\n",
    "        ####################################\n",
    "        ##  データ分割\n",
    "        ##  説明変数と目的変数に分ける。\n",
    "        ##  説明変数はカテゴリデータと連続データに分ける。\n",
    "        ####################################\n",
    "        x_cate = df_x[categ_cols].copy()\n",
    "        x_cont = df_x[contin_cols].copy()\n",
    "        x_id = df_x[index_cols].copy()\n",
    "        x_id = x_id.astype('int64')\n",
    "        \n",
    "        return x_cate , x_cont  ,x_id\n",
    "    \n",
    "    \n",
    "    # 開催日の月を取り出す\n",
    "    def get_month(self, x):\n",
    "        return int(x[0:2])\n",
    "    \n",
    "    # 開催日の曜日を取り出す\n",
    "    def get_week(self, x):\n",
    "        return x[6:7]\n",
    "    \n",
    "    # 開催日の月を取り出す\n",
    "    def get_hour(self, x):\n",
    "        return int(x[0:2])\n",
    "    \n",
    "    # 第〇節の値を取り出して数値化する\n",
    "    def get_match(self, x):\n",
    "        return int(x[x.find('第') + 1: x.find('節')])\n",
    "    \n",
    "    # 湿度を数値化する\n",
    "    def get_humidity(self, x):\n",
    "        return float(x[:-1])/100\n",
    "    \n",
    "    # 放送するテレビ局の数を数える\n",
    "    def get_num(self, x):\n",
    "        return len(x.split('／'))\n",
    "\n",
    "    def dropCol(self):\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=['gameday', 'tv'  ], axis=1)\n",
    "        # application_typeは使ってみる\n",
    "        \n",
    "        self.x_cont_conv = self.x_cont_conv.drop(columns=['year'], axis=1)\n",
    "        # credit_scoreは使ってみる（差があるかは要確認）\n",
    "        \n",
    "    def stageConv(self):\n",
    "        \n",
    "        col = 'stage'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='Ｊ１']        \n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        # ALL ゼロがＪ２なので処理しない\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='Ｊ２']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "        \n",
    "        \n",
    "    def monthConv(self):\n",
    "        \n",
    "        col = 'month'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='12']\n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        # 12月だけ観客数が多いので、その他は０にする\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='03']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='04']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='05']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='06']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='07']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='08']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='09']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='10']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='11']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "    \n",
    "    def weekConv(self):\n",
    "        \n",
    "        col = 'week'\n",
    "        \n",
    "        self.x_cate_conv[col + '_1'] = 0\n",
    "\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='土']\n",
    "        self.x_cate_conv.loc[row_index, col + '_1'] = 1\n",
    "        \n",
    "        # 土曜日だけ観客数が多いので、その他は０にする\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='日']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='月']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='火']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='水']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='木']\n",
    "        row_index = self.x_cate.index[self.x_cate[col]=='金']\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate_conv.drop(columns=col ,axis=1)\n",
    "    \n",
    "    \n",
    "    def train_Split(self):\n",
    "        \n",
    "        # 訓練データと検証データに分割\n",
    "        x_train_cate, x_test_cate ,y_train, y_test = train_test_split(self.x_cate_conv, self.df_y, test_size=0.2, random_state=3) \n",
    "        \n",
    "        # カテゴリデータと同じ行数分数値データを抽出する (id も訓練データと検証データに分ける)\n",
    "        row_index = x_train_cate.index.values\n",
    "        x_train_cont = self.x_cont_conv.loc[row_index, :]\n",
    "        self.X_train_id = self.x_id.loc[row_index, :]\n",
    "        self.X_train_id.reset_index(drop=True, inplace=True)\n",
    "        y_train_capa = self.df_y_capa.loc[row_index, :]\n",
    "        \n",
    "        ###　検証データ\n",
    "        row_index = x_test_cate.index.values\n",
    "        x_test_cont = self.x_cont_conv.loc[row_index, :]\n",
    "        self.X_test_id = self.x_id.loc[row_index, :]\n",
    "        self.X_test_id.reset_index(drop=True, inplace=True)\n",
    "        y_test_capa = self.df_y_capa.loc[row_index, :]\n",
    "        \n",
    "        x_train = pd.concat([x_train_cate , x_train_cont] , axis=1)\n",
    "        x_test = pd.concat([x_test_cate , x_test_cont] , axis=1)\n",
    "        \n",
    "        self.X_train = np.array(x_train)\n",
    "        self.X_test = np.array(x_test)\n",
    "        self.Y_train = np.array(y_train)\n",
    "        self.Y_test = np.array(y_test)\n",
    "        self.Y_train_capa = np.array(y_train_capa)\n",
    "        self.Y_test_capa = np.array(y_test_capa)\n",
    "        \n",
    "        self.coti_size = self.x_cont.shape[1]\n",
    "        self.in_size  = self.X_train.shape[1]\n",
    "        self.out_size = self.Y_train.shape[1]  \n",
    "    \n",
    "    def DataConv(self):\n",
    "        \n",
    "        self.stageConv()\n",
    "        #self.termConv()\n",
    "        self.monthConv()\n",
    "        self.weekConv()\n",
    "        self.dropCol()        \n",
    "        self.train_Split()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1952 entries, 0 to 1952\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   stage_1  1952 non-null   int64\n",
      " 1   month_1  1952 non-null   int64\n",
      " 2   week_1   1952 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 141.0 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1952 entries, 0 to 1952\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   match_num  1952 non-null   int64\n",
      " 1   tv_num     1952 non-null   int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 125.8 KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takasaki\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_1</th>\n",
       "      <th>month_1</th>\n",
       "      <th>week_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stage_1  month_1  week_1\n",
       "0           1        0       1\n",
       "1           1        0       1\n",
       "2           1        0       1\n",
       "3           1        0       1\n",
       "4           1        0       1\n",
       "...       ...      ...     ...\n",
       "1948        0        0       0\n",
       "1949        0        0       0\n",
       "1950        0        0       1\n",
       "1951        0        0       0\n",
       "1952        0        0       0\n",
       "\n",
       "[1952 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x_cate_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, 28,  2],\n",
       "       [ 0,  0,  1, 20,  2],\n",
       "       [ 1,  0,  1, 11,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, 34,  3],\n",
       "       [ 0,  0,  1, 21,  2],\n",
       "       [ 0,  0,  0, 42,  3]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(TrainDataset):\n",
    "    def __init__(self, x_desc):\n",
    "        \n",
    "        # 学習データ\n",
    "        data = pd.read_csv('test.csv')\n",
    "\n",
    "        # スタジアム\n",
    "        self.stadium = pd.read_csv('stadium.csv')\n",
    "        data_all = pd.merge(data, self.stadium, left_on='stadium', right_on='name', how='left') \n",
    "        \n",
    "        # data_allのnameカラムを削除して、data_allに代入してください。\n",
    "        data_all = data_all.drop(columns=['name'])\n",
    "        \n",
    "        # 不正データの補正 (レコード削除のパターンもあるため、ファイル読み込み直後に処理する)\n",
    "        data_all = self.correction(data_all.copy())\n",
    "        \n",
    "        # 目的変数の格納\n",
    "        self.x_cate , self.x_cont, self.x_id = self.DataChange(data_all.copy())\n",
    "        self.x_desc = x_desc\n",
    "        \n",
    "        self.x_cate_conv = self.x_cate.copy()\n",
    "        self.x_cont_conv = self.x_cont.copy()\n",
    "        \n",
    "        # データの加工（標準化や対数化など）\n",
    "        #self.std_scale = 0\n",
    "        self.max_scale = 0\n",
    "        #self.dobule_scale = 0\n",
    "        #self.polynomialFlg = 0\n",
    "        #self.binSplitFlg = 0\n",
    "        #self.logFlg  = 0\n",
    "        self.DataConv()\n",
    "        \n",
    "        #self.NpToPy()\n",
    "        #self.num = len(self.x_cate)\n",
    "        self.num = len(self.x_cate_conv)\n",
    "        self.coti_size = self.x_cont_conv.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_vat[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num\n",
    "    \n",
    "    def train_Split(self):\n",
    "        \n",
    "        #x_temp = self.x_cont.copy()\n",
    "        tmp_cate = np.array(self.x_cate_conv)\n",
    "        tmp_cont = np.array(self.x_cont_conv)\n",
    "        \n",
    "        # numpy の値を torch の値に変換する\n",
    "        self.X_vat_cate = tmp_cate\n",
    "        self.X_vat_cont = tmp_cont\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\takasaki\\Anaconda3\\envs\\matplotlib\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(train_dataset.x_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LR()\n",
    "lr.fit(train_dataset.X_train, train_dataset.Y_train_capa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id   capa\n",
      "0   15087  26530\n",
      "1   15357  22563\n",
      "2   14934  63700\n",
      "3   15467  20588\n",
      "4   14442  15589\n",
      "5   14699  15589\n",
      "6   14399  21292\n",
      "7   16214  15100\n",
      "8   14625  20000\n",
      "9   15354  15454\n",
      "10  14031  19694\n",
      "11  15040  20281\n",
      "12  15705  26530\n",
      "13  16084  15100\n",
      "14  14127  20000\n",
      "15  15209  20000\n",
      "16  15774  24490\n",
      "17  15105  24490\n",
      "18  14539  19637\n",
      "19  15576  25250\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.X_train_id.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15046.]\n",
      " [ 7709.]\n",
      " [37065.]\n",
      " ...\n",
      " [ 5310.]\n",
      " [ 7077.]\n",
      " [ 5894.]]\n",
      "[[14388]\n",
      " [ 5318]\n",
      " [46649]\n",
      " ...\n",
      " [ 3706]\n",
      " [10573]\n",
      " [ 3560]]\n"
     ]
    }
   ],
   "source": [
    "# 予測\n",
    "y_pred_train = lr.predict(train_dataset.X_train)\n",
    "df_pred_train = pd.DataFrame(y_pred_train , columns=['vat_tmp'])\n",
    "\n",
    "# capa を結合して観客数を求める\n",
    "df_pred_train = pd.concat([train_dataset.X_train_id , df_pred_train] , axis=1)\n",
    "df_pred_train['vat'] = df_pred_train['vat_tmp'] * df_pred_train['capa']\n",
    "\n",
    "y_pred_train = np.round(np.array(df_pred_train['vat']))\n",
    "y_pred_train = y_pred_train.reshape(-1,1)\n",
    "print(y_pred_train)\n",
    "print(train_dataset.Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5459.2424916208865\n"
     ]
    }
   ],
   "source": [
    "rmse_train = np.sqrt(MSE(train_dataset.Y_train, y_pred_train))\n",
    "print(rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(train_dataset.X_test)\n",
    "df_pred_test = pd.DataFrame(y_pred_test , columns=['vat_tmp'])\n",
    "\n",
    "# capa を結合して観客数を求める\n",
    "df_pred_test = pd.concat([train_dataset.X_test_id , df_pred_test] , axis=1)\n",
    "df_pred_test['vat'] = df_pred_test['vat_tmp'] * df_pred_test['capa']\n",
    "\n",
    "y_pred_test = np.round(np.array(df_pred_test['vat']))\n",
    "y_pred_test = y_pred_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4798.119240444562\n"
     ]
    }
   ],
   "source": [
    "rmse_test = np.sqrt(MSE(train_dataset.Y_test, y_pred_test))\n",
    "print(rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
